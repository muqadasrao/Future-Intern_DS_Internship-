# -*- coding: utf-8 -*-
"""spam email detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nSpKTAdkl1My-F-xCP0jvJoAWdigQfkj
"""

!pip install scikit-learn tensorflow

# Import necessary libraries
import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.neural_network import MLPClassifier
# Instead of 'keras.preprocessing.text', use 'tensorflow.keras.preprocessing'
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt

#upload data
from google.colab import files
uploaded = files.upload()

#display 5 rows
df = pd.read_csv('spam.csv', encoding='latin-1')
df.head()

import re

# Preprocess the text data
def preprocess_text(text):
    # Remove non-alphanumeric characters (except space)
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    # Convert to lowercase
    text = text.lower()
    return text

# Apply the preprocessing function to the 'message' column
df['cleaned_message'] = df['text'].apply(preprocess_text)

# Display the cleaned data
#NOTE: df was misspelled as 'dataframf'
df[['label', 'cleaned_message']].head() #dataframf is now df

# Split the data into features (X) and labels (y)
X = df['cleaned_message']
y = df['label'].map({'ham': 0, 'spam': 1})  # Convert labels to binary (ham = 0, spam = 1)

# Split the dataset into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize TF-IDF Vectorizer
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)

# Fit and transform the training data, and transform the test data
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Check the shape of the transformed data
X_train_tfidf.shape, X_test_tfidf.shape

# Initialize the MLPClassifier (Feedforward Neural Network)
mlp_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)

# Train the model
mlp_model.fit(X_train_tfidf, y_train)

# Make predictions on the test set
y_pred_mlp = mlp_model.predict(X_test_tfidf)

# Evaluate the MLP model's performance
print("MLP Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_mlp))
print("Precision:", precision_score(y_test, y_pred_mlp))
print("Recall:", recall_score(y_test, y_pred_mlp))
print("F1 Score:", f1_score(y_test, y_pred_mlp))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_mlp))

# Convert text into sequences
tokenizer = Tokenizer(num_words=5000, lower=True)
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences to ensure uniform input size
X_train_pad = pad_sequences(X_train_seq, padding='post', maxlen=100)
X_test_pad = pad_sequences(X_test_seq, padding='post', maxlen=100)

# Build the LSTM model
lstm_model = Sequential()
lstm_model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))
lstm_model.add(SpatialDropout1D(0.2))
lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
lstm_model.add(Dense(1, activation='sigmoid'))

# Compile the model
lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the LSTM model
history = lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test), verbose=1)

# Evaluate the LSTM model's performance
y_pred_lstm = (lstm_model.predict(X_test_pad) > 0.5).astype(int)

print("LSTM Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_lstm))
print("Precision:", precision_score(y_test, y_pred_lstm))
print("Recall:", recall_score(y_test, y_pred_lstm))
print("F1 Score:", f1_score(y_test, y_pred_lstm))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lstm))

# Plot training & validation accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

!pip install keras-tuner

from kerastuner import HyperModel
from kerastuner.tuners import RandomSearch

# Define a hypermodel for tuning LSTM
class LSTMHyperModel(HyperModel):
    def build(self, hp):
        model = Sequential()
        model.add(Embedding(input_dim=5000, output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64), input_length=100))
        model.add(SpatialDropout1D(0.2))

        model.add(LSTM(hp.Int('units', min_value=64, max_value=256, step=64), dropout=0.2, recurrent_dropout=0.2))
        model.add(Dense(1, activation='sigmoid'))

        model.compile(loss='binary_crossentropy', optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']), metrics=['accuracy'])

        return model

# Initialize the tuner
tuner = RandomSearch(
    LSTMHyperModel(),
    objective='val_accuracy',
    max_trials=5,
    executions_per_trial=1,
    directory='my_dir',
    project_name='lstm_tuning'
)

# Perform hyperparameter search
tuner.search(X_train_pad, y_train, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test))

# Get the best model from the tuner
best_lstm_model = tuner.get_best_models(num_models=1)[0]

# Evaluate the best model
y_pred_lstm_best = (best_lstm_model.predict(X_test_pad) > 0.5).astype(int)

print("Optimized LSTM Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_lstm_best))
print("Precision:", precision_score(y_test, y_pred_lstm_best))
print("Recall:", recall_score(y_test, y_pred_lstm_best))
print("F1 Score:", f1_score(y_test, y_pred_lstm_best))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lstm_best))

# Install required libraries
!pip install keras-tuner tensorflow

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from kerastuner import HyperModel
from kerastuner.tuners import RandomSearch
import tensorflow as tf

# Check TensorFlow and Keras version
print("TensorFlow version:", tf.__version__)

# Sample Data Preparation (Replace this with your actual dataset)
# Assuming you have a list of texts (emails) and their corresponding labels (1 for spam, 0 for not spam)
texts = ["Sample email text 1", "Sample email text 2", "Sample email text 3"]  # Replace with your actual email data
labels = [0, 1, 0]  # Replace with your actual labels (1 for spam, 0 for not spam)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer.fit_transform(texts).toarray()
y = np.array(labels)

# Split the data into training and testing sets
X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Define a hypermodel for tuning MLP
class MLPHyperModel(HyperModel):
    def build(self, hp):
        model = Sequential()
        model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=128, step=32),
                        activation='relu', input_shape=(X_train_tfidf.shape[1],)))
        model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))
        model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=128, step=32),
                        activation='relu'))
        model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))
        model.add(Dense(1, activation='sigmoid'))

        model.compile(loss='binary_crossentropy',
                      optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']),
                      metrics=['accuracy'])

        return model

# Initialize the tuner
tuner = RandomSearch(
    MLPHyperModel(),
    objective='val_accuracy',
    max_trials=5,
    executions_per_trial=1,
    directory='my_dir',
    project_name='mlp_tuning'
)

# Perform hyperparameter search
tuner.search(X_train_tfidf, y_train, epochs=5, batch_size=64, validation_data=(X_test_tfidf, y_test))

# Get the best model from the tuner
best_mlp_model = tuner.get_best_models(num_models=1)[0]

# Evaluate the best model
y_pred_mlp_best = (best_mlp_model.predict(X_test_tfidf) > 0.5).astype(int)

# Output the performance metrics
print("Optimized MLP Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_mlp_best))
print("Precision:", precision_score(y_test, y_pred_mlp_best))
print("Recall:", recall_score(y_test, y_pred_mlp_best))
print("F1 Score:", f1_score(y_test, y_pred_mlp_best))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_mlp_best))

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

# Load your dataset (replace 'your_data.csv' with your actual data file)
# Assuming your data is in a CSV format; adjust the delimiter as necessary
# For example: df = pd.read_csv('your_data.csv', delimiter='\t')
data = {
    "label": ["ham", "ham", "ham", "spam", "ham"],
    "text": [
        "Subject: enron methanol ; meter # : 988291",
        "Subject: hpl nom for january 9 , 2001",
        "Subject: neon retreat ho ho ho , we ' re ar",
        "Subject: photoshop , windows , office . cheap",
        "Subject: re : indian springs this deal is t."
    ]
}

# Create a DataFrame
df = pd.DataFrame(data)

# Map labels to binary values: ham -> 0, spam -> 1
df['label'] = df['label'].map({'ham': 0, 'spam': 1})

# Split data into features and labels
texts = df['text'].values
labels = df['label'].values

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

# Initialize TF-IDF Vectorizer with bigram and trigram options
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 3))

# Fit and transform on the training text data
X_train_tfidf = vectorizer.fit_transform(X_train)

# Only transform on the test text data
X_test_tfidf = vectorizer.transform(X_test)

# Verify the transformation
print("Shape of TF-IDF training data:", X_train_tfidf.shape)
print("Shape of TF-IDF test data:", X_test_tfidf.shape)

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Create the MLP model
def create_mlp_model(input_dim):
    model = Sequential()
    model.add(Dense(units=64, activation='relu', input_dim=input_dim))
    model.add(Dropout(0.5))  # Dropout for regularization
    model.add(Dense(units=32, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(units=1, activation='sigmoid'))  # Output layer for binary classification

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Initialize and train the model
mlp_model = create_mlp_model(X_train_tfidf.shape[1])  # Input shape is the number of features
mlp_model.fit(X_train_tfidf, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Step 4: Evaluate the Model
# Make predictions on the test set
y_pred_mlp_probs = mlp_model.predict(X_test_tfidf)
# Convert probabilities to binary predictions and flatten the array
y_pred_mlp = (y_pred_mlp_probs > 0.5).astype(int).flatten() # flatten the prediction to a 1D array

# Ensure both are integers and check shapes
y_test = y_test.astype(int)
y_pred_mlp = y_pred_mlp.astype(int)

# Print shapes to debug
print("y_test shape:", y_test.shape)
print("y_pred_mlp shape:", y_pred_mlp.shape)

# Check for NaN values
print("NaN in y_test:", np.isnan(y_test).sum())
print("NaN in y_pred_mlp:", np.isnan(y_pred_mlp).sum())

# Calculate performance metrics
try:
    accuracy = accuracy_score(y_test, y_pred_mlp)
    precision = precision_score(y_test, y_pred_mlp)
    recall = recall_score(y_test, y_pred_mlp)
    f1 = f1_score(y_test, y_pred_mlp)

    # Print the results
    print("MLP Model Performance:")
    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1 Score:", f1)
except Exception as e:
    print("Error in calculating metrics:", e)

from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
import joblib

# Example: Creating a sample dataset
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Example: Training a model
model = LogisticRegression()
model.fit(X_train, y_train)

# Save the trained model to a .pkl file
joblib.dump(model, 'spam_detection_model.pkl')
print("Model saved as spam_detection_model.pkl")

from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import pandas as pd

# Assuming X_train is your numerical data
# Create a DataFrame with a 'text' column containing string representations
df_X_train = pd.DataFrame(X_train)
df_X_train['text'] = df_X_train.apply(lambda row: ' '.join(map(str, row)), axis=1)

# Create the TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform on the 'text' column of the DataFrame
X_train_tfidf = vectorizer.fit_transform(df_X_train['text'])

# Save the vectorizer
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Load your dataset (ensure this is the correct path and format)
# Example: Replace this with your actual data loading process
data = pd.DataFrame({
    'text': ["Sample email text 1", "Sample email text 2", "Subject: hpl nom for january 9 , 2001",
             "Subject: photoshop , windows , office . cheap ...", "Subject: neon retreat"],
    'label': [0, 0, 0, 1, 0]  # 0 for ham, 1 for spam
})

# Prepare the dataset
texts = data['text']
labels = data['label']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

# Create the TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Create the MLP model
def create_mlp_model(input_dim):
    model = Sequential()
    model.add(Dense(units=64, activation='relu', input_dim=input_dim))
    model.add(Dropout(0.5))
    model.add(Dense(units=32, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(units=1, activation='sigmoid'))  # Output layer for binary classification

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Initialize and train the model
mlp_model = create_mlp_model(X_train_tfidf.shape[1])
mlp_model.fit(X_train_tfidf, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Predict using the MLP model
y_pred_mlp_probs = mlp_model.predict(X_test_tfidf)
y_pred_mlp = (y_pred_mlp_probs > 0.5).astype(int).flatten()  # Flatten the prediction to a 1D array

# Calculate the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_mlp)

# Visualize the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Not Spam', 'Spam'],
            yticklabels=['Not Spam', 'Spam'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Assuming y_test are the true labels and y_pred_mlp are the predicted labels from your model
y_pred_mlp = (mlp_model.predict(X_test_tfidf) > 0.5).astype(int)

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred_mlp)
precision = precision_score(y_test, y_pred_mlp)
recall = recall_score(y_test, y_pred_mlp)
f1 = f1_score(y_test, y_pred_mlp)

# Set up the figure
fig, ax = plt.subplots(figsize=(8, 6))

# Performance Metrics Bar Chart
metrics = [accuracy, precision, recall, f1]
metrics_labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
ax.bar(metrics_labels, metrics, color=['blue', 'orange', 'green', 'red'])
ax.set_ylim(0, 1)
ax.set_title('Performance Metrics')
ax.set_ylabel('Score')

# Add data labels on top of each bar
for i, v in enumerate(metrics):
    ax.text(i, v + 0.01, f"{v:.2f}", ha='center', fontweight='bold')

# Show the plots
plt.tight_layout()
plt.show()

from sklearn.metrics import roc_curve, auc

# Calculate the ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_mlp)
roc_auc = auc(fpr, tpr)

# Plotting the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label='AUC = %0.2f' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

X_new = X_test[1100]
print(y_test[200]) # Changed Y_test to y_test

prediction = loaded_model.predict(X_new)
print(prediction)

if (prediction[0]==0):
  print('Negative Tweet')
else:
  print('Positive Tweet')